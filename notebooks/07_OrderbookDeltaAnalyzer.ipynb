{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbba41f-1d82-4f2d-9a90-01613957a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "A trading bot for this strategy is written in Rust [here](https://github.com/dineshpinto/orderbook-delta-bot).\n",
    "\n",
    "The idea behind this is the concept of _mean reversion_. We look for large deviations in the volume delta of BTC-PERP\n",
    "on FTX at depth=1. These deviations could be caused by over-enthusiastic and over-leveraged market participants (\n",
    "speculation, are reasons important?).\n",
    "\n",
    "### Live orderbook visualizer\n",
    "\n",
    "Built with Dash and Plotly, you can also visualize the orderbook delta live:\n",
    "\n",
    "#### To run the visualizer\n",
    "\n",
    "```shell\n",
    "python src/orderbook_delta_visualizer.py\n",
    "```\n",
    "\n",
    "#### To adjust the visualizer parameters or strategy\n",
    "+ All strategies and parameters are stored in `src/orderbook_delta_strategies.py`\n",
    "+ Modify the strategy by implementing a new class inheriting from the `orderbook_delta_strategies/BaseStrategy` abstract\n",
    "  base class\n",
    "+ Point to the new strategy by modifying the parameters stored in the dataclass `orderbook_delta_strategies/Parameters`\n",
    "+ You can modify parameters when `src/orderbook_delta_visualizer.py` is running, it will restart automatically\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "baf26e7c-7d0b-4e53-a30d-ebd88bd060b5",
   "metadata": {},
   "source": [
    "Run `orderbook_delta_generator.py`, this full scipt will take around 5 hours as the data is not available from any historical sources and needs to be collected live.\n",
    "You can run the analyzer while `orderbook_delta_generator.py` is running as the data is saved at every point. The data is stored in a csv with the following columns:\n",
    "\n",
    "\n",
    "| Name             | Symbol                 | Formula                                                 |\n",
    "|------------------|------------------------|---------------------------------------------------------|\n",
    "| `spot_bid_price` | $P_{\\text{bid, spot}}$ | ---                                                     |\n",
    "| `spot_ask_price` | $P_{\\text{ask, spot}}$ | ---                                                     |\n",
    "| `perp_bid_price` | $P_{\\text{bid, perp}}$ | ---                                                     |\n",
    "| `perp_ask_price` | $P_{\\text{ask, perp}}$ | ---                                                     |\n",
    "| `spot_delta`     | $\\Delta_{\\text{spot}}$ | $$ V_{\\text{bid, spot}}(d) - V_{\\text{ask, spot}}(d) $$ |\n",
    "| `perp_delta`     | $\\Delta_{\\text{perp}}$ | $$ V_{\\text{bid, perp}}(d) - V_{\\text{ask, perp}}(d) $$ |\n",
    "| `delta_div`      | $\\Delta_{\\text{div}}$  | $$ \\Delta_{\\text{spot}}(d) - \\Delta_{\\text{perp}}(d) $$ |\n",
    "\n",
    "where, \n",
    "$$d = \\text{depth of the orderbook}$$\n",
    "$$V(d) = \\text{volume of order on the books at depth } d$$\n",
    "\n",
    "The idea behind this is the concept of _mean reversion_. \n",
    "We look for deviations in the perp orderbook $\\Delta_{\\text{perp}}$ at $d=0$ that are larger than 3 standard deviations \n",
    "from a 21 period rolling bollinger band. These deviations could be caused by over-excited and over-leveraged market participants.\n",
    "\n",
    "We counter trade those deviations, with the positions such that:\n",
    "\n",
    "| Trigger                                          | Position |\n",
    "|--------------------------------------------------|----------|\n",
    "| $$\\Delta_{\\text{perp}} > BB(21)_{\\text{upper}}$$ | short    |\n",
    "| $$\\Delta_{\\text{perp}} < BB(21)_{\\text{lower}}$$ | long     |\n",
    "\n",
    "We are testing this with `BTC-PERP` on FTX, which has good liquidity and small spreads. In principle, the scheme could be modified for lower liquidity pairs too, perhaps by adjusting the bollinger band width and length for generating triggers."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Limitations\n",
    "\n",
    "+ This model is not based on a detailed analysis of market microstructure and order-book dynamics, it is simply an\n",
    "  observation based on very limited experimentation\n",
    "+ To understand market microstucture and order-book dynamics, an ab-initio theoretical analysis is required. Quant arXiv\n",
    "  has some nice papers on this:\n",
    "    + [Trade arrival dynamics and quote imbalance in a limit order book](https://arxiv.org/pdf/1312.0514.pdf)\n",
    "    + [Continuous-time Modeling of Bid-Ask Spread and Price Dynamics in Limit Order Books](https://arxiv.org/pdf/1310.1103.pdf)\n",
    "    + [How markets slowly digest changes in supply and demand](https://arxiv.org/pdf/0809.0822.pdf)\n",
    "+ The data is certainly over-fit\n",
    "+ Needs to tested on significantly more data\n",
    "\n",
    "### TODO\n",
    "\n",
    "+ Extract probabilities to use as inputs for Kelly criterion\n",
    "+ Use multiple statical models to predict market moves (in progress, needs to be formalized)\n",
    "    - [x] ARIMA\n",
    "    - [x] Observed Components\n",
    "    - [x] ML time series analysis\n",
    "+ Perform spectral analysis for market timing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae466866-0cb7-4ea0-8995-fbf8763d1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERBOOK_PATHS = [os.path.join(\"..\", \"data\", \"19-03-2022_13-31_delta.csv\"), \n",
    "                   os.path.join(\"..\", \"data\", \"19-03-2022_17-30_delta.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe531805-1ebd-42f2-bad9-d1f20eca1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profitability(df_orders: pd.DataFrame) -> list:\n",
    "    \"\"\" \n",
    "        Extract profitability of trades based on positions taken. \n",
    "        - For long entries we enter with the ask price and exit with the bid price\n",
    "        - For short entries we enter with the bid price and exit with the ask price\n",
    "    \"\"\"\n",
    "    entry = None\n",
    "    position = None\n",
    "\n",
    "    profits = []\n",
    "    profit = 0\n",
    "    for row in df_orders.itertuples(index=True):\n",
    "        if entry:\n",
    "            if position == \"long\":\n",
    "                exit = row.bid_price\n",
    "            elif position == \"short\":\n",
    "                exit = row.ask_price\n",
    "\n",
    "        if position == \"long\":\n",
    "            profit += exit - entry\n",
    "        elif position == \"short\":\n",
    "            profit += entry - exit\n",
    "\n",
    "        if row.position == \"long\":\n",
    "            entry = row.ask_price\n",
    "            position = \"long\"\n",
    "        elif row.position == \"short\":\n",
    "            entry = row.bid_price\n",
    "            position = \"short\"\n",
    "\n",
    "        profits.append(profit)\n",
    "        # print(row.Index, row.price, row.position, position, profit)\n",
    "    return profits\n",
    "\n",
    "def trigger_conditions(trigger_set: int) -> pd.Series:\n",
    "    \"\"\" Define logical conditions for long/short positions \"\"\"\n",
    "    c1 = df.perp_delta < perp_delta_bbands.iloc[:, 0]\n",
    "    c2 = df.perp_delta > perp_delta_bbands.iloc[:, 2]\n",
    "    \n",
    "    c3 = df.perp_bid_price > perp_bid_price_bbands.iloc[:, 0]\n",
    "    c4 = df.perp_bid_price < perp_bid_price_bbands.iloc[:, 2]\n",
    "    \n",
    "    if trigger_set == 0:\n",
    "        return c1\n",
    "    elif trigger_set == 1:\n",
    "        return c2\n",
    "    elif trigger_set == 2:\n",
    "        return c1 & (c3 | c4)\n",
    "    elif trigger_set == 3:\n",
    "        return c2 & (c3 | c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eff58b-ca52-41d5-9b48-ca934a50e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for orderbook_paths in ORDERBOOK_PATHS:\n",
    "    _df = pd.read_csv(orderbook_paths, index_col=\"time\").drop(\"Unnamed: 0\", axis=1)\n",
    "    _df.drop_duplicates(inplace=True)\n",
    "    df = pd.concat([df, _df], ignore_index=False, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05dd08b-1ecd-453c-9f83-75a9dcbd9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ORDERBOOK_PATHS[1], index_col=\"time\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0e710-831b-44b1-b090-06f8c05def84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77142b7-6cc3-45b4-a4ee-a513d763f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBAND1_LEN = 20\n",
    "BBAND2_LEN = 10\n",
    "STD = 3\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True)\n",
    "\n",
    "# Plot spot and perp deltas\n",
    "fig.append_trace(go.Scatter(x=df.index, y=df.spot_delta, mode=\"markers\", name=\"Spot Delta\", \n",
    "                            marker=dict(color=\"#ff7f0e\", size=3, symbol='cross-open')), row=1, col=1)\n",
    "fig.append_trace(go.Scatter(x=df.index, y=df.perp_delta, mode=\"markers\", name=\"Perp Delta\", \n",
    "                            marker=dict(color=\"#9467bd\", size=3, symbol='circle-open')), row=1, col=1)\n",
    "\n",
    "\n",
    "# Plot perp delta bollinger bands\n",
    "perp_delta_bbands = ta.bbands(df[\"perp_delta\"], length=BBAND1_LEN, std=STD)\n",
    "fig.append_trace(go.Scatter(x=df.index, y=perp_delta_bbands.iloc[:, 0], mode=\"lines\", name=\"Lower Bollinger Band\", \n",
    "                            line_color=\"#d62728\", line_width=0.5), row=1, col=1)\n",
    "fig.append_trace(go.Scatter(x=df.index, y=perp_delta_bbands.iloc[:, 2], mode=\"lines\", name=\"Upper Bollinger Band\", \n",
    "                            line_color=\"#2ca02c\", line_width=0.5), row=1, col=1)\n",
    "\n",
    "# Plot spot and perp bid prices\n",
    "fig.append_trace(go.Scatter(x=df.index, y=df.spot_bid_price, mode=\"markers\", name=\"Spot Bid Price\", \n",
    "                            marker=dict(color=\"#ff7f0e\", size=3, symbol='cross-open')), row=2, col=1)\n",
    "#fig.append_trace(go.Scatter(x=df.index, y=df.spot_ask_price, mode=\"markers\", name=\"Spot Ask Price\", \n",
    "#                            marker=dict(color=\"red\", size=4, symbol='cross-open')), row=2, col=1)\n",
    "fig.append_trace(go.Scatter(x=df.index, y=df.perp_bid_price, mode=\"markers\", name=\"Perp Bid Price\",\n",
    "                            marker=dict(color=\"#9467bd\", size=3, symbol='circle-open')), row=2, col=1)\n",
    "#fig.append_trace(go.Scatter(x=df.index, y=df.perp_ask_price, mode=\"markers\", name=\"Perp Ask Price\",\n",
    "#                            marker=dict(color=\"red\", size=4, symbol='circle-open')), row=2, col=1)\n",
    "\n",
    "# Plot perp bid price bollinger bands\n",
    "perp_bid_price_bbands = ta.bbands(df[\"perp_bid_price\"], length=BBAND2_LEN, std=STD)\n",
    "fig.append_trace(go.Scatter(x=df.index, y=perp_bid_price_bbands.iloc[:, 0], mode=\"lines\", name=\"Lower Bollinger Band\", \n",
    "                            line_color=\"#d62728\", line_width=0.5), row=2, col=1)\n",
    "fig.append_trace(go.Scatter(x=df.index, y=perp_bid_price_bbands.iloc[:, 2], mode=\"lines\", name=\"Upper Bollinger Band\", \n",
    "                            line_color=\"#2ca02c\", line_width=0.5), row=2, col=1)\n",
    "\n",
    "# Get all entries and exits in a DataFrame, and plot them\n",
    "df_orders = pd.DataFrame(columns=[\"time\", \"bid_price\", \"ask_price\", \"position\"])\n",
    "idx = 0\n",
    "for index in df.index[trigger_conditions(trigger_set=0)]:\n",
    "    fig.add_vline(x=index, line_dash=\"dot\", row=2, col=1, line=dict(color=\"#d62728\"))\n",
    "    df_orders.loc[idx] = [index, df.perp_bid_price[index], df.perp_ask_price[index], \"short\"]\n",
    "    idx += 1\n",
    "for index in df.index[trigger_conditions(trigger_set=1)]:\n",
    "    fig.add_vline(x=index, line_dash=\"dash\", row=2, col=1, line=dict(color=\"#2ca02c\"))\n",
    "    df_orders.loc[idx] = [index, df.perp_bid_price[index], df.perp_ask_price[index], \"long\"]\n",
    "    idx += 1\n",
    "\n",
    "# Compute profitability and plot result\n",
    "df_orders = df_orders.set_index(\"time\").sort_index()\n",
    "fig.append_trace(go.Scatter(x=df_orders.index, y=get_profitability(df_orders), mode=\"markers+lines\", name=\"Profit\", \n",
    "                            marker=dict(color=\"#1f77b4\", size=4, symbol='circle-open')), row=3, col=1)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Delta\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Price\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Profit\", row=3, col=1)\n",
    "\n",
    "fig.update_layout(height=700, width=1200)\n",
    "fig.show()\n",
    "\n",
    "# fig.write_image(os.path.join(\"..\", \"images\", \"orderbook_delta_analyzer.png\"))\n",
    "# fig.write_html(os.path.join(\"..\", \"images\", \"orderbook_delta_analyzer.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041215f5-7c6c-47ba-8a4d-b76d3b796c92",
   "metadata": {},
   "source": [
    "# Simple Optimizer\n",
    "\n",
    "Optimize to max profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f8867-463e-475b-9d97-83258d77efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f4adb-e0bf-4e4c-bab4-efd48891ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbands_lens = [10, 15, 20, 21, 25, 30]\n",
    "stds = [2, 2.5, 3, 3.5, 4]\n",
    "\n",
    "profit = np.zeros(len(bbands_lens) * len(bbands_lens) * len(stds))\n",
    "\n",
    "iterator = tqdm(itertools.product(bbands_lens, bbands_lens, stds))\n",
    "\n",
    "for _idx, (bbands_len1, bbands_len2, std) in enumerate(iterator):\n",
    "    perp_delta_bbands = ta.bbands(df[\"perp_delta\"], length=bbands_len1, std=std)\n",
    "    perp_bid_price_bbands = ta.bbands(df[\"perp_bid_price\"], length=bbands_len2, std=std)\n",
    "\n",
    "    df_orders = pd.DataFrame(columns=[\"time\", \"bid_price\", \"ask_price\", \"position\"])\n",
    "    idx = 0\n",
    "    for index in df.index[trigger_conditions(trigger_set=0)]:\n",
    "        df_orders.loc[idx] = [index, df.perp_bid_price[index], df.perp_ask_price[index], \"short\"]\n",
    "        idx += 1\n",
    "    for index in df.index[trigger_conditions(trigger_set=1)]:\n",
    "        df_orders.loc[idx] = [index, df.perp_bid_price[index], df.perp_ask_price[index], \"long\"]\n",
    "        idx += 1\n",
    "\n",
    "    # Compute profitability and plot result\n",
    "    df_orders = df_orders.set_index(\"time\").sort_index()\n",
    "\n",
    "    profits = get_profitability(df_orders)\n",
    "    if len(profits) == 0:\n",
    "        profit[_idx] = 0\n",
    "    else:\n",
    "        profit[_idx] = profits[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f790480c-ced4-44be-a876-933bbdb9df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _idx, (bbands_len1, bbands_len2, std) in enumerate(itertools.product(bbands_lens, bbands_lens, stds)):\n",
    "    if _idx == np.argmax(profit):\n",
    "        print(f\"Max profit of {profit[_idx]} at BBAND_LEN=({bbands_len1}, {bbands_len2}), STD={std}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73557dae-5260-4505-8cd9-908c44fc2dee",
   "metadata": {},
   "source": [
    "# Position sizing with Kelly criterion\n",
    "\n",
    "Position sizing using Kelly criterion\n",
    "\n",
    "$$ f* = p + \\frac{p - 1}{b} $$\n",
    "\n",
    "where,  \n",
    "$f*$ is the fraction of the  size of the position to take  \n",
    "$p$ is the probability of a win  \n",
    "$b$ is the fraction gained on winning  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87427352-0262-4d86-981e-c3e9bf724240",
   "metadata": {},
   "source": [
    "We restrict the space to set of values \n",
    "\n",
    "$ b \\in [1.05, 2] $  \n",
    "$ p \\in [0.1, 1] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5b700-b111-4b8b-b7a0-241e6b7a6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelly_size(p: np.ndarray, b: float) -> np.ndarray:\n",
    "    return p + (p - 1) / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23466a4e-8872-4ebb-a79b-c982163191fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = np.linspace(0.1, 1, 10)\n",
    "fraction_gained = np.arange(1.05, 2, 0.15)\n",
    "\n",
    "fig2 = go.Figure()\n",
    "    \n",
    "for b in fraction_gained:\n",
    "    fraction = kelly_size(probability, b)\n",
    "    \n",
    "    fig2.add_trace(\n",
    "        go.Scatter(\n",
    "            x=p, \n",
    "            y=fraction, \n",
    "            mode=\"markers+lines\", \n",
    "            name=f\"b={b:.2f}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# fig2.update_xaxes(type=\"log\")\n",
    "\n",
    "fig2.update_layout(\n",
    "    xaxis_title=\"Probability p\",\n",
    "    yaxis_title=\"Kelly size f*\",\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c87465-4e47-428b-9e94-69ab02526e91",
   "metadata": {},
   "source": [
    "# Time series analysis\n",
    "\n",
    "## Looking for\n",
    "1. Seasonal patterns\n",
    "2. Cyclical patterns\n",
    "\n",
    "\n",
    "## Some concerns:\n",
    "1. Correlated erros\n",
    "2. Cross-validation\n",
    "3. Lookahead\n",
    "4. Sationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7366f35-1f3e-4408-b931-23265e3ac39e",
   "metadata": {},
   "source": [
    "# Deriving Time series\n",
    "\n",
    "## Linear regression\n",
    "Based on standard linear regression \n",
    "\n",
    "$$ \\textbf{y}_i = \\beta \\textbf{x}_i^T + \\epsilon_i, \\quad i \\in [1, n] $$\n",
    "\n",
    "where $\\epsilon_i \\in N(0, \\sigma^2)$\n",
    "\n",
    "\n",
    "from this we can derive a likelihood function which can be defined as:\n",
    "\n",
    "$$ L(\\beta, \\sigma^2) = p(Y | X, \\beta, \\sigma^2) $$\n",
    "\n",
    "Based on the structure of the $h(X, \\beta, \\sigma)$ we can formulate four different criteria,\n",
    "\n",
    "1. Mean Absolute deviation $$ h \\equiv | y_i - \\beta \\textbf{x}_i^T |$$\n",
    "2. Least squares $$ h \\equiv (y_i - \\beta \\textbf{x}_i^T)^2 $$\n",
    "3. Maximum likelihood $$ h \\equiv -log( p(y | \\beta, \\sigma^2, \\textbf{x}_i^T)) $$\n",
    "4. Quantile estimator \n",
    "\n",
    "$$\n",
    "\\tau \\in [0, 1]\\\\\n",
    "\\begin{equation}\n",
    "  h\\equiv\n",
    "  \\begin{cases}\n",
    "    \\tau | y_i - \\beta \\textbf{x}_i^T |, & \\text{if } y_i \\geq \\beta \\textbf{x}_i \\\\\n",
    "    (1 - \\tau) | y_i - \\beta \\textbf{x}_i^T |, & \\text{if } y_i < \\beta \\textbf{x}_i\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994ab8a-a5f1-4bf8-ae3c-cc97fa5262de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERBOOK_PATHS = [os.path.join(\"..\", \"data\", \"19-03-2022_13-31_delta.csv\"), \n",
    "                   os.path.join(\"..\", \"data\", \"19-03-2022_17-30_delta.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373364b9-41f8-402e-9f6e-5de65863b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ORDERBOOK_PATHS[1], index_col=\"time\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80db86-db9d-4d53-bba7-741a42789600",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_scatter(\n",
    "    x=df.index,\n",
    "    y=df[\"perp_delta\"],\n",
    "    name=\"Perp delta\",\n",
    "    mode=\"markers+lines\",\n",
    "    marker=dict(size=4)\n",
    ")\n",
    "\n",
    "fig.add_scatter(\n",
    "    x=df.index,\n",
    "    y=df[\"spot_delta\"],\n",
    "    name=\"Spot delta\",\n",
    "    mode=\"markers+lines\",\n",
    "    marker=dict(size=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3cd499-aaaa-444b-883b-08c8cbb9948b",
   "metadata": {},
   "source": [
    "# ARIMA(p, d, q) modeling\n",
    "\n",
    "$$ \\left(1 - \\sum_{i=1}^{p} \\phi_iL^i \\right) (1 - L)^d X_t = \\left(1 + \\sum_{i=1}^{q}\\theta_iL^i \\right)\\epsilon_t $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc798d5b-75cf-4558-b4f6-a375ebaecbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3d89d-64af-44cb-85a0-046c7aa19901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef4624-e8ab-414a-b2e3-2f76c93bb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(df.perp_delta.dropna())\n",
    "print(f\"p-value = {result[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b0590-f9a1-42f1-a0b9-d036aff7ad6d",
   "metadata": {},
   "source": [
    "$d = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf0b7b-8249-4934-a091-0cb327e3b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# PACF plot of 1st differenced series\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].plot(df.perp_delta.diff())\n",
    "ax[0].set_title('1st Differencing')\n",
    "\n",
    "plot_pacf(df.perp_delta.diff().dropna(), ax=ax[1], method=\"ywm\")\n",
    "ax[1].set_xlim(-1, 20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d3011-047d-404a-8ea8-0d206ebe209d",
   "metadata": {},
   "source": [
    "This gives us $p=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb4623-4524-40f9-8fe3-6026f3cfdb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(df.perp_delta.diff())\n",
    "ax[0].set_title('1st Differencing')\n",
    "\n",
    "plot_acf(df.perp_delta.diff().dropna(), ax=ax[1])\n",
    "ax[1].set_xlim(-1, 20)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7371a-ba80-453c-afcc-25ea870760c5",
   "metadata": {},
   "source": [
    "Let's set $q = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964a1ce-559c-4ecc-984c-7bac068bc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.statespace.SARIMAX(df.perp_delta, order=(1, 1, 0))\n",
    "model_fit = model.fit(disp=False)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afcde3-1a06-4c13-8105-2cf0e060c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Plot residual errors\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "# residuals.reset_index(inplace=True, drop=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db6b27-9f71-4ec2-94f1-22f02370bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_fit.get_prediction()\n",
    "predict_ci = predict.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08107ff-5aa5-406a-9db3-a7fc8b2340c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "df.perp_delta.plot(ax=ax, style='-', label='Observed')\n",
    "predict.predicted_mean.plot(ax=ax, style='-', label='One-step-ahead forecast')\n",
    "# ax.fill_between(predict_ci.index, predict_ci.iloc[:, 0], predict_ci.iloc[:, 1], color='r', alpha=0.1)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e77cf-6782-4e89-8f8a-638c9e21f68d",
   "metadata": {},
   "source": [
    "# Unobserved Components Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349182a8-5286-4617-81e2-dd2dc95e0f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"level\": \"smooth trend\",\n",
    "    \"cycle\": False,\n",
    "    \"seasonal\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a419e-635b-4e4f-a4c6-9b2da47ac13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uo_mod = sm.tsa.UnobservedComponents(df.perp_delta, **model)\n",
    "uo_res = uo_mod.fit()\n",
    "print(uo_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674495f8-4142-4806-a614-856b61560ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = uo_res.plot_components(figsize=(10, 6))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44205d07-34bb-483f-94a9-d3e741d7d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 20\n",
    "predict_res = uo_res.get_prediction(dynamic=df.shape[0] - num_steps)\n",
    "\n",
    "predict = predict_res.predicted_mean\n",
    "predict_ci = predict_res.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000308c-ffd7-4512-ae60-210532e16066",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df.perp_delta, label=\"Observed\")\n",
    "ax.plot(df.index[:-num_steps], predict[:-num_steps], label=\"One step ahead\")\n",
    "\n",
    "ax.plot(df.index[-num_steps:], predict[-num_steps:], label=\"Multistep\")\n",
    "# ax.fill_between(predict_ci.index, predict_ci.iloc[:, 0], predict_ci.iloc[:, 1], alpha=0.1)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ad412",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ML based time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d68766-d419-40ca-b6fb-c0f40c2fbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93687bde-f9ea-43f0-ab98-d7f0f7ac5674",
   "metadata": {},
   "outputs": [],
   "source": [
    "perp = df[['perp_delta']]\n",
    "perp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeffa69-992c-4e43-821f-805333c47f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "perp[\"perp_delta\"] = scaler.fit_transform(perp[\"perp_delta\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbdda6-71f5-4304-adfb-2d319f272710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(perp_delta, lookback):\n",
    "    data_raw = perp_delta.to_numpy() # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - lookback): \n",
    "        data.append(data_raw[index: index + lookback])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    test_set_size = int(np.round(0.2*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size:,:-1]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "    \n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "\n",
    "lookback = 20 # choose sequence length\n",
    "x_train, y_train, x_test, y_test = split_data(perp, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f46bb7-f536-441b-b230-e9cb6e680150",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train.shape = ',x_train.shape)\n",
    "print('y_train.shape = ',y_train.shape)\n",
    "print('x_test.shape = ',x_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d8f84-7414-489e-ab62-c3bc01239c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "y_train_gru = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test_gru = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68818b0b-7b31-43d1-a148-0e4f77fce714",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8dc1f6-5cf4-484b-a13f-8e9f2c0bb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c13d2-8663-42be-92e7-0f57f21c3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02596915-ae54-46b2-ac95-eed4cebc2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "start_time = time.time()\n",
    "lstm = []\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    y_train_pred = model(x_train)\n",
    "\n",
    "    loss = criterion(y_train_pred, y_train_lstm)\n",
    "    print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "training_time = time.time()-start_time\n",
    "print(\"Training time: {}\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721f239-5be3-4ef9-b72f-49ef704624b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.DataFrame(scaler.inverse_transform(y_train_pred.detach().numpy()))\n",
    "original = pd.DataFrame(scaler.inverse_transform(y_train_lstm.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94746b3a-5e8b-492d-9a08-8a485b44d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")    \n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ax = sns.lineplot(x = original.index, y = original[0], label=\"Data\", color='royalblue')\n",
    "ax = sns.lineplot(x = predict.index, y = predict[0], label=\"Training Prediction (LSTM)\", color='tomato')\n",
    "ax.set_title('Perp Delta', size = 14, fontweight='bold')\n",
    "ax.set_ylabel(\"Delta Volume (BTC)\", size = 14)\n",
    "ax.set_xticklabels('', size=10)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ax = sns.lineplot(data=hist, color='royalblue')\n",
    "ax.set_xlabel(\"Epoch\", size = 14)\n",
    "ax.set_ylabel(\"Loss\", size = 14)\n",
    "ax.set_title(\"Training Loss\", size = 14, fontweight='bold')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae243864-2e44-45d9-b57a-d4b72806df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# make predictions\n",
    "y_test_pred = model(x_test)\n",
    "\n",
    "# invert predictions\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
    "y_train = scaler.inverse_transform(y_train_lstm.detach().numpy())\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(y_test_lstm.detach().numpy())\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "lstm.append(trainScore)\n",
    "lstm.append(testScore)\n",
    "lstm.append(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96f212-41b0-4137-b73e-0c4bcaf9a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(perp)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[lookback:len(y_train_pred)+lookback, :] = y_train_pred\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(perp)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(y_train_pred)+lookback-1:len(perp)-1, :] = y_test_pred\n",
    "\n",
    "original = scaler.inverse_transform(perp['perp_delta'].values.reshape(-1,1))\n",
    "\n",
    "predictions = np.append(trainPredictPlot, testPredictPlot, axis=1)\n",
    "predictions = np.append(predictions, original, axis=1)\n",
    "result = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85acd1d-a6b5-4ff4-a669-0e16f05c9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(go.Scatter(x=result.index, y=result[2],\n",
    "                    mode='lines',\n",
    "                    name='Actual Value')))\n",
    "fig.add_trace(go.Scatter(go.Scatter(x=result.index, y=result[0],\n",
    "                    mode='lines',\n",
    "                    name='Train prediction')))\n",
    "fig.add_trace(go.Scatter(x=result.index, y=result[1],\n",
    "                    mode='lines',\n",
    "                    name='Test prediction'))\n",
    "\n",
    "\n",
    "\n",
    "annotations = []\n",
    "annotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n",
    "                              xanchor='left', yanchor='bottom',\n",
    "                              text='Results (GRU)',\n",
    "                              font=dict(family='Rockwell',\n",
    "                                        size=26,\n",
    "                                        color='white'),\n",
    "                              showarrow=False))\n",
    "fig.update_layout(annotations=annotations)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market_analytics",
   "language": "python",
   "name": "market_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
